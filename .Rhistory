# load in the libraries we'll need
library(tidyverse)
library(tidytext)
install.packages("tidytext")
# load in the libraries we'll need
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
# load in the libraries we'll need
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
# load in the libraries we'll need
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
# load in the libraries we'll need
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
df = fread("/home/aishwarya/Documents/Academia/Sem 5/DA/DA19_A2_Datasets/tweets_kabir_singh.csv")
df = fread("/home/aishwarya/Documents/Academia/Sem 5/DA/DA19_A2_Datasets/dataset/tweets_kabir_singh.csv")
install.packages("bit64")
# load in the libraries we'll need
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
library(bit64)
# load in the libraries we'll need
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
library(bit64)
df = fread("/home/aishwarya/Documents/Academia/Sem 5/DA/DA19_A2_Datasets/dataset/tweets_kabir_singh.csv")
df
df <- select(df, time, author, author_id, text)
df
df <- select(df, author, text)
df
df[1]
df[1, 1]
df[1]
df[1]
df[1, 2]
get_sentiments("afinn")
install.packages("textdata")
get_sentiments("afinn")
get_sentiments("afinn")
get_sentiments("bing")
get_sentiments("nrc")
df <- select(df, author, text)
df
# tokenize
tokens <- data_frame(text = df$text) %>% unnest_tokens(word, text)
# tokenize
tokens <- tibble(text = df$text) %>% unnest_tokens(word, text)
# tokenize
tokens <- tibble(text = df$text) %>% unnest_tokens(word, text)
tokens
tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
# load in the libraries we'll need
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
library(bit64)
library(ggplot2)
df = fread("/home/aishwarya/Documents/Academia/Sem 5/DA/DA19_A2_Datasets/dataset/tweets_kabir_singh.csv")
df <- select(df, author, text)
get_sentiments("afinn")
get_sentiments("nrc")
get_sentiments("bing")
get_sentiments("afinn")
get_sentiments("nrc")
get_sentiments("bing")
# tokenize
tokens <- tibble(text = df$text) %>% unnest_tokens(word, text)
tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
tokens %>%
inner_join(get_sentiments("afinn")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
tokens %>%
inner_join(get_sentiments("afinn")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
kabir_singh_sentiment <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
kabir_singh_sentiment <- tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
ggplot(kabir_singh_sentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
ggplot(kabir_singh_sentiment, aes(index, sentiment))
ggplot(kabir_singh_sentiment, aes(sentiment))
bing_word_counts <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
bing_word_counts %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
# load in the libraries we'll need
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
library(bit64)
library(ggplot2)
library(wordcloud)
install.packages("wordcloud")
# load in the libraries we'll need
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
library(bit64)
library(ggplot2)
library(wordcloud)
tidy_books %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100))
tokens %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100))
# load in the libraries we'll need
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
library(bit64)
library(ggplot2)
library(wordcloud)
library(reshape2)
# load in the libraries we'll need
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
library(bit64)
library(ggplot2)
library(wordcloud)
library(reshape2)
tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"),
max.words = 100)
tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("cornflower_blue", "gray80"),
max.words = 100)
tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("cornflowerblue", "gray80"),
max.words = 100)
tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("cornflowerblue", "red"),
max.words = 100)
tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("red", "cornflowerblue"),
max.words = 100)
kabir_singh_sentiment <- tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
kabir_singh_sentiment <- tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
kabir_singh_sentiment
tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
ggplot(kabir_singh_sentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
ggplot(kabir_singh_sentiment, aes(index, sentiment) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
ggplot(kabir_singh_sentiment, aes(index, sentiment))
ggplot(kabir_singh_sentiment, aes(index, sentiment))
ggplot(kabir_singh_sentiment, aes(x=sentiment))
#ggplot(kabir_singh_sentiment, aes(x=sentiment))
# load in the libraries we'll need
# Reference : https://www.tidytextmining.com/sentiment.html
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
library(bit64)
library(ggplot2)
library(wordcloud)
library(reshape2)
df = fread("/home/aishwarya/Documents/Academia/Sem 5/DA/DA19_A2_Datasets/dataset/tweets_kabir_singh.csv")
df <- select(df, author, text)
get_sentiments("afinn")
get_sentiments("nrc")
get_sentiments("bing")
# tokenize
tokens <- tibble(text = df$text) %>% unnest_tokens(word, text)
tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
kabir_singh_sentiment <- tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
kabir_singh_sentiment
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
bing_word_counts %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
tokens %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100))
tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("red", "cornflowerblue"),
max.words = 100)
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
hist(bing_word_counts)
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
hist(x=bing_word_counts$word, y=bing_word_counts$n)
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
hist(x=bing_word_counts$word, y=bing_word_counts$n)
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
hist(x=bing_word_counts$word, y=bing_word_counts$n)
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
hist(x=bing_word_counts$word[10], y=bing_word_counts$n)
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
hist(x=bing_word_counts$word[0:100])
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
hist(x=bing_word_counts$n)
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
barplot(height = bing_word_counts$n)
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
barplot(height = bing_word_counts$n, names.arg = bing_word_counts$word)
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
barplot(height = bing_word_counts$n[0:10], names.arg = bing_word_counts$word[0:10])
bing_word_counts <- tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
#mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) #%>% # made data wide rather than narrow
#mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative owrds
# load in the libraries we'll need
# Reference : https://www.tidytextmining.com/sentiment.html
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
library(bit64)
library(ggplot2)
library(wordcloud)
library(reshape2)
df = fread("/home/aishwarya/Documents/Academia/Sem 5/DA/DA19_A2_Datasets/dataset/tweets_kabir_singh.csv")
df <- select(df, author, text)
get_sentiments("afinn")
get_sentiments("nrc")
get_sentiments("bing")
# load in the libraries we'll need
# Reference : https://www.tidytextmining.com/sentiment.html
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
library(data.table)
library(dplyr)
library(bit64)
library(ggplot2)
library(wordcloud)
library(reshape2)
more_sentiments <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
barplot(more_sentiments)
more_sentiments <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
barplot(more_sentiments[1])
more_sentiments <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
more_sentiments[1]
barplot(more_sentiments[1])
more_sentiments <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
more_sentiments[1]
barplot(more_sentiments[1:10])
more_sentiments <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
more_sentiments[1]
barplot(table(more_sentiments))
more_sentiments <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
table(more_sentiments)
barplot(table(more_sentiments))
more_sentiments <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
table(more_sentiments)[1]
barplot(table(more_sentiments))
more_sentiments <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
table(more_sentiments)[0]
barplot(table(more_sentiments))
more_sentiments <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentiment words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) # # of positive words - # of negative words
table(more_sentiments)[2]
barplot(table(more_sentiments))
